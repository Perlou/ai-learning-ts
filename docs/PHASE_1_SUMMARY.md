# AI 学习阶段性总结 (Phase 1 - Phase 4)

本文档总结了我们在 `ai-learning-ts` 项目中学习的核心概念和实战代码。

## 1. 核心概念 (Core Concepts)

### 1.1 LLM (大语言模型)

- **本质**：LLM 不是知识库，而是 **“下一个词元预测引擎”**。它根据概率生成文本。
- **幻觉 (Hallucination)**：因为是基于概率生成，模型可能会自信地编造事实。
- **无状态 (Stateless)**：API 不会记住你之前说过的话。要实现对话，必须每次将完整的 **Context (上下文)** 发送给模型。

### 1.2 Tokens (词元)

- 模型处理的最小单位不是单词，而是 Token。
- 英文通常 1 Token ≈ 0.75 单词。
- Token 数量限制了 **Context Window (上下文窗口)** 的大小。

### 1.3 Embeddings (嵌入) —— AI 的“理解”

- **定义**：将文本转换为高维向量（一组数字）。
- **原理**：在数学空间中，语义相似的文本，其向量距离更近。
- **作用**：它是搜索、推荐和 RAG 的基石。
- **实战结论**：我们通过代码验证了 `Cat` 和 `Dog` 的向量距离远小于 `Cat` 和 `Apple`。

## 2. RAG (检索增强生成)

RAG 是解决 LLM “幻觉”和“知识过时”问题的关键技术。

### 2.1 流程

1.  **索引 (Indexing)**：将私有数据（知识库）转换为 Embeddings 并存储。
2.  **检索 (Retrieval)**：将用户问题转换为 Embedding，在知识库中搜索最相似的内容。
3.  **生成 (Generation)**：将检索到的内容作为“上下文”喂给 LLM，让它回答问题。

### 2.2 优势

- **私有数据**：让 AI 能回答关于你个人或公司内部的问题。
- **可控性**：限制 AI 只能基于提供的上下文回答，减少胡编乱造。

## 3. 实战代码回顾

我们通过 4 个 TypeScript 脚本循序渐进地掌握了这些技能：

| 文件名               | 功能             | 核心知识点                                          |
| :------------------- | :--------------- | :-------------------------------------------------- |
| `01-hello-gemini.ts` | 发送简单提示词   | API 基础调用，环境配置                              |
| `02-chatbot.ts`      | 命令行聊天机器人 | **Context (上下文)** 管理，`startChat` 保持会话记忆 |
| `03-embeddings.ts`   | 生成向量并比较   | **Embeddings** 原理，向量相似度计算                 |
| `04-simple-rag.ts`   | 简易 RAG 系统    | **RAG 完整闭环**：索引 -> 检索 -> 生成              |

## 4. 下一步计划

- 学习 **Vercel AI SDK**，构建 Web 界面。
- 探索真正的 **向量数据库** (如 Pinecone)。
- 尝试 **Agent (智能体)** 开发。
