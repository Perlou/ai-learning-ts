# 第 3 阶段测验：Embeddings 与 RAG

> **测验说明**：本测验涵盖 Embeddings、向量相似度和 RAG 系统的核心知识点。

---

## 第一部分：Embeddings 基础（35 分）

### 1. 单选题（每题 4 分，共 20 分）

**1.1** Embeddings 的核心作用是什么？

- A. 压缩文本以节省存储空间
- B. 将文本转换为向量，使语义相似的文本在向量空间中距离更近
- C. 加密文本内容
- D. 将文本翻译成其他语言

<details>
<summary>点击查看答案</summary>

**答案：B**

**解释**：Embeddings 将文本转换为高维向量，使得语义相似的文本向量距离更近，这是语义搜索的基础。

</details>

---

**1.2** 以下哪个文本对的向量距离最近？

- A. "汽车" 和 "苹果"
- B. "猫" 和 "狗"
- C. "电脑" 和 "香蕉"
- D. "天空" 和 "桌子"

<details>
<summary>点击查看答案</summary>

**答案：B**

**解释**："猫" 和 "狗" 都是动物，语义相关性最强，因此向量距离最近。

</details>

---

**1.3** Gemini 的 `text-embedding-004` 模型生成的向量维度是多少？

- A. 256 维
- B. 512 维
- C. 768 维
- D. 1536 维

<details>
<summary>点击查看答案</summary>

**答案：C**

**解释**：`text-embedding-004` 生成 768 维的向量。

</details>

---

**1.4** 在生产环境中，推荐使用哪种相似度计算方法？

- A. 欧几里得距离
- B. 曼哈顿距离
- C. 余弦相似度
- D. 汉明距离

<details>
<summary>点击查看答案</summary>

**答案：C**

**解释**：余弦相似度不受向量长度影响，只关注方向，是向量检索的首选方法。

</details>

---

**1.5** 余弦相似度的值范围是多少？

- A. 0 到 1
- B. -1 到 1
- C. 0 到 ∞
- D. -∞ 到 +∞

<details>
<summary>点击查看答案</summary>

**答案：B**

**解释**：余弦相似度范围是 -1 到 1，其中 1 表示完全相同的方向，-1 表示完全相反，0 表示正交。

</details>

---

### 2. 判断题（每题 3 分，共 15 分）

**2.1** Embeddings 可以理解同义词，即使两个词完全不同，只要语义相似，向量就会接近。

<details>
<summary>点击查看答案</summary>

**答案：正确（✅）**

**解释**：这正是 Embeddings 的核心优势，能够理解语义而非单纯匹配关键词。

</details>

---

**2.2** 欧几里得距离和余弦相似度计算结果是一样的。

<details>
<summary>点击查看答案</summary>

**答案：错误（❌）**

**解释**：两者是不同的计算方法。欧几里得距离考虑向量长度，余弦相似度只看方向。

</details>

---

**2.3** 向量维度越高，计算相似度的时间就越长。

<details>
<summary>点击查看答案</summary>

**答案：正确（✅）**

**解释**：高维向量需要更多的计算，768 维比 256 维慢。

</details>

---

**2.4** 余弦相似度的值越大，表示两个向量越相似。

<details>
<summary>点击查看答案</summary>

**答案：正确（✅）**

**解释**：余弦相似度范围是 -1 到 1，值越接近 1 表示越相似。

</details>

---

**2.5** Embeddings 模型只能用于英文文本，不支持中文。

<details>
<summary>点击查看答案</summary>

**答案：错误（❌）**

**解释**：现代 Embedding 模型（如 text-embedding-004）都支持多语言，包括中文。

</details>

---

## 第二部分：RAG 系统（40 分）

### 3. 单选题（每题 4 分，共 20 分）

**3.1** RAG 代表什么？

- A. Retrieval-Augmented Generation
- B. Random Access Generation
- C. Reinforced AI Generation
- D. Rapid Answer Generator

<details>
<summary>点击查看答案</summary>

**答案：A**

**解释**：RAG 是 Retrieval-Augmented Generation（检索增强生成）的缩写。

</details>

---

**3.2** RAG 系统的三个核心阶段按顺序是？

- A. 生成 → 索引 → 检索
- B. 索引 → 检索 → 生成
- C. 检索 → 索引 → 生成
- D. 索引 → 生成 → 检索

<details>
<summary>点击查看答案</summary>

**答案：B**

**解释**：RAG 流程是：1) 索引（将文档向量化）→ 2) 检索（找相关文档）→ 3) 生成（基于文档回答）。

</details>

---

**3.3** RAG 主要解决 LLM 的什么问题？

- A. 响应速度慢
- B. 幻觉（编造信息）和知识过时
- C. 成本过高
- D. API 调用限制

<details>
<summary>点击查看答案</summary>

**答案：B**

**解释**：RAG 通过检索真实文档来提供准确信息，减少幻觉，并且知识库可以实时更新。

</details>

---

**3.4** 在 RAG 的检索阶段，如何找到最相关的文档？

- A. 随机选择
- B. 选择最长的文档
- C. 计算问题向量与文档向量的相似度并排序
- D. 按时间顺序选择

<details>
<summary>点击查看答案</summary>

**答案：C**

**解释**：通过计算余弦相似度等方法，找出与问题最相关的文档。

</details>

---

**3.5** 在 RAG 的 Prompt 中，为什么要加上"如果上下文中没有答案，请说不知道"？

- A. 节省 Token
- B. 防止 LLM 基于训练数据编造答案
- C. 提高生成速度
- D. 美化输出格式

<details>
<summary>点击查看答案</summary>

**答案：B**

**解释**：这是约束 LLM 的行为，确保它只基于提供的上下文回答，而不是依赖训练数据编造。

</details>

---

### 4. 实践题（20 分）

**4.1 设计 RAG 系统（10 分）**

假设你需要为公司的技术文档构建一个 RAG 问答系统。现有 100 篇技术文档。

请回答：

1. 索引阶段需要做什么？（3 分）
2. 用户提问后，检索阶段的步骤是什么？（4 分）
3. 如何确保 LLM 的回答准确？（3 分）

<details>
<summary>点击查看参考答案</summary>

**参考答案**：

**1. 索引阶段**（3 分）：

- 将 100 篇文档分块（按段落或主题）
- 为每个文档块生成 Embedding 向量
- 存储到向量数据库（或内存数组），包含原文和向量

**2. 检索阶段**（4 分）：

- 将用户问题转换为 Embedding 向量
- 计算问题向量与所有文档向量的余弦相似度
- 按相似度降序排序
- 返回 Top-K（如 Top 3）最相关文档

**3. 确保准确性**（3 分）：

- 在 Prompt 中明确要求"只基于上下文回答"
- 设置相似度阈值，过滤不相关文档
- 在回答中引用原文
- 如果没有相关文档，诚实说"不知道"
</details>

---

**4.2 代码分析题（10 分）**

以下代码实现了向量检索，请回答问题：

```typescript
const rankedDocs = vectorStore
  .map((doc) => ({
    ...doc,
    score: cosineSimilarity(queryVector, doc.embedding),
  }))
  .sort((a, b) => b.score - a.score);

const bestMatch = rankedDocs[0];
```

**问题**：

1. 这段代码做了什么？（4 分）
2. 为什么要 `b.score - a.score` 而不是 `a.score - b.score`？（3 分）
3. 如果要返回 Top 3 最相关文档，应该怎么修改？（3 分）

<details>
<summary>点击查看参考答案</summary>

**答案**：

**1. 代码功能**（4 分）：

- 遍历向量存储中的所有文档
- 计算每个文档与问题的余弦相似度
- 将文档按相似度得分排序
- 取出相似度最高的文档（Top 1）

**2. 排序方向**（3 分）：

- `b.score - a.score` 是降序排序（从大到小）
- 因为余弦相似度越大表示越相似
- 所以要把最大的分数排在最前面

**3. 返回 Top 3**（3 分）：

```typescript
const top3 = rankedDocs.slice(0, 3);
```

</details>

---

## 第三部分：综合应用（25 分）

### 5. 场景题

**5.1 问题诊断（15 分）**

你实现了一个 RAG 系统，但遇到以下问题。请分析原因和解决方案：

**场景 A**：用户问 "如何重置密码？"，但 RAG 返回了关于"如何修改用户名"的文档。

**问题**：

1. 可能的原因是什么？（5 分）
2. 如何解决？（5 分）

<details>
<summary>点击查看参考答案</summary>

**原因**（5 分）：

- Embedding 模型认为"重置密码"和"修改用户名"语义接近（都是账号操作）
- 知识库中可能没有关于密码的文档
- 文档分割不当，两个话题混在一起

**解决方案**（5 分）：

- 优化文档分割粒度，确保每个块主题单一
- 增加密码相关的文档到知识库
- 提高检索数量（Top 3 而非 Top 1），让 LLM 从多个文档中选择
- 添加元数据过滤（如分类标签）
- 使用更好的 Embedding 模型
</details>

---

**场景 B**：RAG 系统检索到了正确的文档，但 LLM 的回答还是包含了不在文档中的内容。

**问题**：如何解决？（5 分）

<details>
<summary>点击查看参考答案</summary>

**解决方案**（5 分）：

- 强化 Prompt 约束，明确要求"只使用上下文信息"
- 添加"不要编造信息"的约束
- 使用更强大的模型（如 Gemini 1.5 Pro）
- 在 Prompt 中提供示例
- 后处理：验证答案是否包含文档中的内容
</details>

---

## 评分标准

- **90-100 分**：优秀！完全掌握 Embeddings 和 RAG
- **75-89 分**：良好，理解核心概念
- **60-74 分**：及格，建议复习实践题
- **60 分以下**：需要重新学习本阶段内容

---

## 📝 学习建议

**如果错误较多**：

1. 重新阅读 [SUMMARY.md](./SUMMARY.md)
2. 运行 `01-embeddings.ts` 和 `02-simple-rag.ts`
3. 修改代码参数，观察向量相似度变化
4. 尝试添加自己的知识库数据

**如果表现良好**：

1. 构建个人笔记的 RAG 系统
2. 尝试使用向量数据库（LanceDB）
3. 进入 [第 4 阶段](../phase-4-agents/README.md) 学习 Agent

---

**完成测验后，恭喜你！** 🎉

你已经掌握了 Embeddings 和 RAG 的核心技能，可以构建智能检索系统了！
