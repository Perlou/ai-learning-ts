import * as dotenv from "dotenv";

dotenv.config();

/**
 * Ollama åŸºç¡€ç¤ºä¾‹
 *
 * æ¼”ç¤ºå¦‚ä½•é€šè¿‡REST APIè°ƒç”¨æœ¬åœ°Ollamaæ¨¡å‹
 *
 * å‰æï¼š
 * 1. å·²å®‰è£…Ollama (brew install ollama)
 * 2. å·²ä¸‹è½½æ¨¡å‹ (ollama pull qwen2.5:7b)
 * 3. OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ
 */

const OLLAMA_API = "http://localhost:11434";

// æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦è¿è¡Œ
async function checkOllamaService(): Promise<boolean> {
  try {
    const response = await fetch(`${OLLAMA_API}/api/tags`);
    if (response.ok) {
      const data = await response.json();
      console.log("âœ… OllamaæœåŠ¡è¿è¡Œä¸­");
      console.log(`ğŸ“¦ å·²å®‰è£…çš„æ¨¡å‹: ${data.models?.length || 0}ä¸ª\n`);
      return true;
    }
  } catch (error) {
    console.error("âŒ OllamaæœåŠ¡æœªè¿è¡Œ");
    console.error("è¯·å…ˆå¯åŠ¨: ollama serve");
    return false;
  }
  return false;
}

// åŸºç¡€æ–‡æœ¬ç”Ÿæˆ
async function generateText(model: string, prompt: string) {
  console.log(`ğŸ¤– ä½¿ç”¨æ¨¡å‹: ${model}`);
  console.log(`ğŸ’¬ æç¤ºè¯: ${prompt}\n`);

  const startTime = Date.now();

  try {
    const response = await fetch(`${OLLAMA_API}/api/generate`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model,
        prompt,
        stream: false, // éæµå¼ï¼Œä¸€æ¬¡æ€§è¿”å›
      }),
    });

    if (!response.ok) {
      const error = await response.text();
      throw new Error(`APIé”™è¯¯: ${error}`);
    }

    const data = await response.json();
    const elapsed = ((Date.now() - startTime) / 1000).toFixed(2);

    console.log("ğŸ“ å›å¤:");
    console.log(data.response);
    console.log(`\nâ±ï¸  è€—æ—¶: ${elapsed}ç§’`);
    console.log(`ğŸ“Š ç”Ÿæˆtokenæ•°: ${data.eval_count || "N/A"}`);

    if (data.eval_count && elapsed) {
      const tokensPerSec = (data.eval_count / parseFloat(elapsed)).toFixed(1);
      console.log(`âš¡ é€Ÿåº¦: ${tokensPerSec} tokens/ç§’`);
    }

    return data.response;
  } catch (error) {
    console.error("âŒ ç”Ÿæˆå¤±è´¥:", error);
    throw error;
  }
}

// æµå¼ç”Ÿæˆï¼ˆé€å­—è¾“å‡ºï¼‰
async function generateStream(model: string, prompt: string) {
  console.log(`\n${"=".repeat(60)}`);
  console.log(`ğŸŒŠ æµå¼ç”Ÿæˆç¤ºä¾‹`);
  console.log(`ğŸ¤– æ¨¡å‹: ${model}`);
  console.log(`ğŸ’¬ æç¤ºè¯: ${prompt}\n`);

  const response = await fetch(`${OLLAMA_API}/api/generate`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model,
      prompt,
      stream: true, // å¯ç”¨æµå¼
    }),
  });

  if (!response.ok || !response.body) {
    throw new Error("Stream failed");
  }

  console.log("ğŸ“ å›å¤: ");

  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  let fullResponse = "";

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    const chunk = decoder.decode(value);
    const lines = chunk.split("\n").filter((l) => l.trim());

    for (const line of lines) {
      try {
        const data = JSON.parse(line);
        if (data.response) {
          process.stdout.write(data.response);
          fullResponse += data.response;
        }
      } catch (e) {
        // å¿½ç•¥è§£æé”™è¯¯
      }
    }
  }

  console.log("\n");
  return fullResponse;
}

// ä¸»å‡½æ•°
async function main() {
  console.log("=== Ollama åŸºç¡€ä½¿ç”¨ç¤ºä¾‹ ===\n");

  // 1. æ£€æŸ¥æœåŠ¡
  const isRunning = await checkOllamaService();
  if (!isRunning) {
    console.log("\nğŸ’¡ å¯åŠ¨æç¤º:");
    console.log("1. å®‰è£…: brew install ollama");
    console.log("2. ä¸‹è½½æ¨¡å‹: ollama pull qwen2.5:7b");
    console.log("3. å¯åŠ¨æœåŠ¡: ollama serve");
    return;
  }

  // ä½¿ç”¨çš„æ¨¡å‹ï¼ˆæ ¹æ®ä½ å®‰è£…çš„æ¨¡å‹ä¿®æ”¹ï¼‰
  const model = "qwen2.5:7b"; // æˆ– 'llama3.1:8b', 'gemma2:2b' ç­‰

  console.log("=".repeat(60));
  console.log("ç¤ºä¾‹ 1: åŸºç¡€æ–‡æœ¬ç”Ÿæˆï¼ˆéæµå¼ï¼‰\n");

  const prompt1 = "ç”¨ä¸€å¥è¯ä»‹ç»TypeScriptçš„ä¼˜åŠ¿";
  await generateText(model, prompt1);

  console.log("\n" + "=".repeat(60));
  console.log("ç¤ºä¾‹ 2: è§£é‡Šæ¦‚å¿µ\n");

  const prompt2 = "è§£é‡Šä»€ä¹ˆæ˜¯é‡å­è®¡ç®—ï¼Œç”¨ç®€å•çš„è¯­è¨€ï¼Œä¸è¶…è¿‡100å­—";
  await generateText(model, prompt2);

  // ç¤ºä¾‹ 3: æµå¼ç”Ÿæˆ
  await generateStream(model, "å†™ä¸€é¦–å…³äºä»£ç çš„äº”è¨€ç»å¥");

  console.log("=".repeat(60));
  console.log("\nğŸ’¡ è§‚å¯Ÿè¦ç‚¹:");
  console.log("1. æœ¬åœ°è¿è¡Œ - æ— éœ€APIå¯†é’¥");
  console.log("2. å®Œå…¨å…è´¹ - æ— è°ƒç”¨æ¬¡æ•°é™åˆ¶");
  console.log("3. éšç§ä¿æŠ¤ - æ•°æ®ä¸ç¦»å¼€æœ¬åœ°");
  console.log("4. æµå¼è¾“å‡º - æå‡ç”¨æˆ·ä½“éªŒ");
  console.log("5. æ¨ç†é€Ÿåº¦ - å–å†³äºç¡¬ä»¶ï¼ˆApple Siliconå¾ˆå¿«ï¼‰");

  console.log("\nğŸ¯ ä¸‹ä¸€æ­¥:");
  console.log("- è¿è¡Œ src/12-ollama-chat.ts å­¦ä¹ å¯¹è¯æ¨¡å¼");
  console.log("- è¿è¡Œ src/13-ollama-embeddings.ts å­¦ä¹ å‘é‡ç”Ÿæˆ");
}

main().catch(console.error);
