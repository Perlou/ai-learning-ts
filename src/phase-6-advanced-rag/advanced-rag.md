# 高级 RAG 技术详解：混合检索与重排序

在基础的 RAG（检索增强生成）系统中，我们通常只使用**向量搜索 (Vector Search)**。虽然向量搜索在理解语义方面非常强大，但在某些场景下它并不完美。

本章我们介绍了两种能够显著提升 RAG 系统准确率的关键技术：**混合检索 (Hybrid Search)** 和 **重排序 (Re-ranking)**。

---

## 1. 混合检索 (Hybrid Search)

### 什么是混合检索？

混合检索是指同时结合 **关键词搜索 (Keyword Search)** 和 **向量搜索 (Vector Search)** 的结果，以获得更全面的检索效果。

- **向量搜索 (Semantic)**：

  - **原理**：将文本转换为向量，计算余弦相似度。
  - **优势**：理解同义词、概念关联（如搜“水果”能找到“苹果”）。
  - **劣势**：对精确匹配（如特定型号、ID、人名）表现不佳；有时会产生“幻觉”般的关联。

- **关键词搜索 (Lexical/BM25)**：
  - **原理**：传统的倒排索引，匹配词汇出现的频率。
  - **优势**：精确匹配能力强，对专有名词敏感。
  - **劣势**：无法理解语义（搜“手机”找不到“移动电话”）。

### 为什么需要它？

想象一下你在搜索公司的内部文档：

1.  **场景 A（概念）**：你搜“如何请假”。
    - 向量搜索表现更好，因为它能理解“请假”、“休假”、“由于私事缺勤”是相关的。
2.  **场景 B（精确）**：你搜错误代码 `ERR-502`。
    - 关键词搜索表现更好。向量搜索可能会找到 `ERR-503` 或其他看起来“相似”的错误，但这并不是你想要的。

通过混合检索，我们能同时兼顾这两种场景。

### 实现原理

通常使用 **RRF (Reciprocal Rank Fusion)** 算法来合并两者的结果。简单来说，就是看一个文档在两个列表中的排名：

- 如果文档 A 在向量搜索排第 1，在关键词搜索排第 1 -> **总分极高**。
- 如果文档 B 在向量搜索排第 1，在关键词搜索没出现 -> **总分中等**。
- 如果文档 C 在两个搜索都没出现 -> **总分 0**。

---

## 2. 重排序 (Re-ranking)

### 什么是重排序？

重排序是一种**两阶段检索 (Two-Stage Retrieval)** 策略：

1.  **第一阶段 (Retrieval)**：使用快速的算法（如向量搜索或混合搜索）从海量数据中召回 Top N 个文档（例如 Top 50）。
    - _特点：速度快，但精度一般。_
2.  **第二阶段 (Re-ranking)**：使用一个更强大、更慢的模型（Cross-Encoder 或 LLM）对这 Top N 个文档进行精细的打分和排序，只保留 Top K（例如 Top 3）。
    - _特点：速度慢，但精度极高。_

### 为什么需要它？

向量搜索使用的是 **Bi-Encoder** 架构：查询和文档是独立编码的。这意味着模型在编码文档时不知道查询是什么，编码查询时不知道文档是什么。它们只是在向量空间中比较距离。

而重排序通常使用 **Cross-Encoder** 架构（或者直接让 LLM 读）：它同时看到“查询”和“文档”，能够深入理解两者之间的逻辑关系。

**比喻：**

- **向量搜索** 就像是在人群中快速扫视，挑出“看起来像嫌疑人”的 50 个人。
- **重排序** 就像是侦探把这 50 个人带到审讯室，逐一仔细盘问，最后确定 3 个真正的嫌疑人。

### 实现方式

在我们的示例 `src/17-reranking.ts` 中，我们使用 Gemini (LLM) 作为重排序器：

1.  先用向量搜索找出 Top 10 个文档。
2.  构建一个 Prompt，把这 10 个文档的内容贴进去。
3.  让 Gemini 扮演“裁判”，给每个文档打分 (0-10) 并给出理由。
4.  根据 Gemini 的打分重新排序。

---

## 总结：构建生产级 RAG 管道

通过本章的学习，我们构建了一个更成熟的 RAG 管道 (Pipeline)：

```mermaid
graph LR
    A[用户查询] --> B{混合检索}
    B -->|向量搜索| C[候选集 1]
    B -->|关键词搜索| D[候选集 2]
    C & D --> E[合并 (RRF)]
    E --> F[Top 50 文档]
    F --> G[重排序 (LLM/Cross-Encoder)]
    G --> H[Top 3 精选文档]
    H --> I[LLM 生成回答]
```

1.  **查询 (Query)**
2.  **召回 (Retrieval)**: 混合搜索，以此保证**召回率 (Recall)**（不错过相关文档）。
3.  **重排序 (Re-ranking)**: 精细打分，以此保证**精确率 (Precision)**（排除不相关文档）。
4.  **生成 (Generation)**: 将最优质的上下文喂给 LLM 生成最终答案。

这就是目前业界构建高性能 RAG 系统的主流架构。
